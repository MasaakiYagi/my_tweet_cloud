{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_load = json.load(open('settings.json', 'r'))\n",
    "CHASEN = json_load[\"CHASEN\"]\n",
    "IMG_PATH = \"img/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetデータの読み込み\n",
    "TWEET_DATA_PATH = \"data/all_tweets.csv\"\n",
    "df = pd.read_csv(TWEET_DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MeCab.Tagger (r\"-d '{}' -O chasen\".format(CHASEN))\n",
    "\n",
    "# 一番ふるい日付を取得。年と月\n",
    "oldedst_date = min(df[\"date\"])\n",
    "\n",
    "# 期間開始日と終了日を生成\n",
    "start_date = datetime.datetime(oldedst_date.year, oldedst_date.month, 1)\n",
    "end_date = start_date + relativedelta(months=1, days=-1)\n",
    "\n",
    "# 本日から見た翌月初日を生成\n",
    "now = datetime.datetime.now()\n",
    "limit_date = datetime.datetime(now.year, now.month, 1) + relativedelta(months=1)\n",
    "\n",
    "cnt = 0\n",
    "while start_date < limit_date:  # 今日からみた翌月になったらループ終了\n",
    "    # 当該期間のデータ抽出\n",
    "    tweets = df[(df[\"date\"]>=start_date)&(df[\"date\"]<=end_date)][\"tweet_text\"]\n",
    "\n",
    "    # wordにわかちがいた名詞をスペース区切りで格納\n",
    "    word=\"\"\n",
    "    for tweet in tweets:\n",
    "        node = m.parseToNode(tweet)\n",
    "        while node:\n",
    "            hinshi = node.feature.split(\",\")[0]\n",
    "            #if hinshi in [\"名詞\",\"動詞\",\"形容詞\"]:\n",
    "            if hinshi in [\"名詞\"]:\n",
    "                origin = node.feature.split(\",\")[6]\n",
    "                word = word + \" \" + origin\n",
    "            node = node.next\n",
    "    \n",
    "    # wordcloudで可視化\n",
    "    fpath = \"./ipaexg.ttf\"\n",
    "    wordcloud = WordCloud(background_color=\"white\",font_path=fpath, width=600,height=400,min_font_size=15)\n",
    "    wordcloud.generate(word)\n",
    "    \n",
    "    # 画像保存\n",
    "    file_name = IMG_PATH + str(cnt) + \"_\" + str(start_date.year) + \"-\" + str(start_date.month) + \".png\"\n",
    "    wordcloud.to_file(file_name)\n",
    "    \n",
    "    # カーソル処理\n",
    "    cnt += 1\n",
    "    start_date += relativedelta(months=1)\n",
    "    end_date = start_date + relativedelta(months=1, days=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11de562e7f7b31501ac02c5f8a69931e07772ac90d4dcf22f4e95bb71187c177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
